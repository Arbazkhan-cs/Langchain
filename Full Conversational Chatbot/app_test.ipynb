{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import UnstructuredCSVLoader\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\", \n",
    "               api_key=os.getenv('GROQ_API_KEY'),\n",
    "               temperature=0.5,\n",
    "               max_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just a language model, I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help you with any questions or tasks you may have! How about you, how's your day going?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi how are you\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a medical AI chatbot. Users ask you medical questions, and you provide accurate and in a simple way answers based on your training data.\n",
    "\n",
    "    Prompt: What is the definition of [medical term]?\n",
    "    How does [medication] work?\n",
    "    What are the side effects of [treatment]?\"\"\"),\n",
    "    (\"human\", \"{input} {agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []\n",
    "agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=template)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Arbaz! I'm a medical AI chatbot here to help answer your questions and provide you with accurate and reliable information about various medical topics. What's on your mind? Do you have a specific question or topic you'd like to discuss?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi my name is arbaz khan',\n",
       " 'output': \"Nice to meet you, Arbaz! I'm a medical AI chatbot here to help answer your questions and provide you with accurate and reliable information about various medical topics. What's on your mind? Do you have a specific question or topic you'd like to discuss?\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Hi my name is arbaz khan\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arbaz Khan\\AppData\\Local\\Temp\\ipykernel_2876\\4596074.py:15: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\Arbaz Khan\\Desktop\\LangChain\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load the CSV file with questions and answers\n",
    "data = pd.read_csv(\"Test.csv\")\n",
    "\n",
    "# Convert the CSV data into LangChain documents\n",
    "documents = [Document(page_content=row['Answer'], metadata={'Question': row['Question']}) for _, row in data.iterrows()]\n",
    "\n",
    "# Initialize an embeddings model and vector store (we'll use FAISS here)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Initialize the RetrievalQA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "# Prompt user for a question and get the answer from the CSV data\n",
    "def chat_with_bot(question):\n",
    "    return qa_chain.run(question)\n",
    "\n",
    "# Example usage\n",
    "user_question = \"What does cartilage link?\"\n",
    "answer = chat_with_bot(user_question)\n",
    "print(\"Bot:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Test.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glycogen is the way the body stores glucose - ...</td>\n",
       "      <td>Sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many square feet is the average adult huma...</td>\n",
       "      <td>19 feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the largest artery in the body?</td>\n",
       "      <td>The aorta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What body system is the liver a part of?</td>\n",
       "      <td>Digestive System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does cartilage link?</td>\n",
       "      <td>Joints and bones</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question            answer\n",
       "0  Glycogen is the way the body stores glucose - ...             Sugar\n",
       "1  How many square feet is the average adult huma...           19 feet\n",
       "2            What is the largest artery in the body?         The aorta\n",
       "3           What body system is the liver a part of?  Digestive System\n",
       "4                          What does cartilage link?  Joints and bones"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [f\"Q: {q}\\nA: {a}\" for q, a in zip(df['question'], df['answer'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q: Glycogen is the way the body stores glucose - better known by what common name?\\nA: Sugar',\n",
       " 'Q: How many square feet is the average adult human’s skin?\\nA: 19 feet',\n",
       " 'Q: What is the largest artery in the body?\\nA: The aorta',\n",
       " 'Q: What body system is the liver a part of?\\nA: Digestive System',\n",
       " 'Q: What does cartilage link?\\nA: Joints and bones']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Q: How many square feet is the average adult human’s skin?\\nA: 19 feet'),\n",
       " Document(page_content='Q: What does cartilage link?\\nA: Joints and bones'),\n",
       " Document(page_content='Q: What is the largest artery in the body?\\nA: The aorta'),\n",
       " Document(page_content='Q: What body system is the liver a part of?\\nA: Digestive System')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"square feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [f\"Q: {q}\\nA: {a}\" for q, a in zip(df['question'], df['answer'])]\n",
    "\n",
    "@tool\n",
    "def get_knowledge(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Provide answer by finding the answer from the database\n",
    "    \"\"\"\n",
    "    global db\n",
    "    return db.similarity_search(question)[0].page_content\n",
    "\n",
    "@tool\n",
    "def add_knowledge(question: str, answer: str) -> None:\n",
    "    \"\"\"\n",
    "    Add the question and answer to the database if not provided\n",
    "    \"\"\"\n",
    "    global db\n",
    "    texts.append(f'Q: {question}\\nA: {answer}')\n",
    "    db = FAISS.from_texts(texts, embeddings)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an helpfull ai agent which follows the below sequence to answer the question:\n",
    "     -> Use get_knowledge tool to get the answer by sending the question as a perameter\n",
    "     -> If can't find the answer then use add_knowledge tool to add the question and answer\"\"\"),\n",
    "     (\"human\", \"{input}{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0.5)\n",
    "tools = [get_knowledge, add_knowledge]\n",
    "agent = create_tool_calling_agent(\n",
    "    llm= llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
